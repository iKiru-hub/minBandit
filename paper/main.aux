\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{unsrt}
\citation{suttonReinforcementLearningProblem1998}
\citation{nivEvolutionReinforcementLearning2002}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{averbeckTheoryChoiceBandit2015}
\citation{suttonReinforcementLearningProblem1998}
\citation{agrawalAnalysisThompsonSampling2012}
\citation{kaufmannThompsonSamplingAsymptotically2012}
\citation{auerFinitetimeAnalysisMultiarmed2002}
\citation{gittinsBanditProcessesDynamic1979}
\citation{banMultifacetContextualBandits2021}
\citation{tokicAdaptiveEGreedyExploration2010}
\citation{tokicValueDifferenceBasedExploration2011}
\citation{schmidgallBraininspiredLearningArtificial2024}
\citation{hassabisNeuroscienceInspiredArtificialIntelligence2017}
\citation{leeBraininspiredPredictiveCoding2022}
\citation{liuSeeingBelievingBrainInspired2023}
\citation{EvaluationBioInspiredModels}
\citation{ReviewNeuroscienceInspiredMachine}
\citation{garivierUpperConfidenceBoundPolicies2008}
\citation{besbesStochasticMultiArmedBanditProblem2014}
\citation{cavenaghiNonStationaryMultiArmed2021}
\citation{odohertyAbstractRewardPunishment2001}
\citation{ricebergRewardStabilityDetermines2012}
\citation{tremblayRelativeRewardPreference1999}
\citation{elliottDissociableFunctionsMedial2000}
\citation{frankAnatomyDecisionStriatoorbitofrontal2006}
\citation{carrollEncodingCertaintyBump2014}
\citation{esnaola-acebesBumpAttractorDynamics2021}
\citation{bariDynamicDecisionMaking2021}
\citation{houstonMatchingBehavioursRewards2021}
\citation{larsenSynapsetypespecificPlasticityLocal2015}
\citation{blackmanTargetcellspecificShorttermPlasticity2013}
\citation{bartolHippocampalSpineHead2015}
\citation{arielIntrinsicVariabilityPv2012}
\citation{inglisModulationDopamineAdaptive2021}
\citation{iigayaAdaptiveLearningDecisionmaking2016}
\citation{toblerAdaptiveCodingReward2005}
\citation{schultzNeuralSubstratePrediction1997}
\citation{didomenicoDopaminergicModulationPrefrontal2023}
\citation{lohaniDopamineModulationPrefrontal2019}
\citation{dardenneRolePrefrontalCortex2012}
\citation{qiForcedExplorationBandit2023}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{3}{section.2}\protected@file@percent }
\citation{lukChoiceCodingFrontal2013}
\citation{kennerleyDecisionMakingReward2011a}
\citation{khamassiChapter22Medial2013}
\citation{funahashiPrefrontalContributionDecisionMaking2017}
\citation{marcosDeterminingMonkeyFree2016}
\citation{balewskiValueDynamicsAffect2023}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Binomial K-armed bandit problem}{4}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Model description}{4}{subsection.2.2}\protected@file@percent }
\citation{martinRepresentationObjectConcepts2007a}
\newlabel{eq:main}{{2.2}{5}{Model description}{equation.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textsc  {Model architecture} - \textit  {The model is composed of a layer $U$ (blue), receiving a feedfoward input $I_{\text  {ext}}$, a layer $V$ (orange), and connections $\textbf  {W}^{UV}$ and $\textbf  {W}^{VU}$. Additionally, two indexes $k_{U}, k_{V}$ are extracted from the layers and corresponds to the selection made by the two populations as $k_{U}=\text  {argmax}_{k} \{\textbf  {u}\}$, $k_{V}=\text  {argmax}_{k} \{\textbf  {v}\}$.}}}{5}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:main_architecture}{{1}{5}{\textsc {Model architecture} - \textit {The model is composed of a layer $U$ (blue), receiving a feedfoward input $I_{\text {ext}}$, a layer $V$ (orange), and connections $\textbf {W}^{UV}$ and $\textbf {W}^{VU}$. Additionally, two indexes $k_{U}, k_{V}$ are extracted from the layers and corresponds to the selection made by the two populations as $k_{U}=\text {argmax}_{k} \{\textbf {u}\}$, $k_{V}=\text {argmax}_{k} \{\textbf {v}\}$.}}{figure.caption.1}{}}
\citation{ockerFlexibleNeuralConnectivity2020}
\citation{apicellaSurveyModernTrainable2021}
\citation{millerCombinedMechanismsNeural2019}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Option selection}{6}{subsubsection.2.2.1}\protected@file@percent }
\citation{backmanEffectsWorkingMemoryTraining2011}
\citation{enelStableDynamicRepresentations2020}
\citation{larsenSynapsetypespecificPlasticityLocal2015}
\citation{citriSynapticPlasticityMultiple2008}
\citation{kennedySynapticSignalingLearning2016}
\citation{samavatSynapticInformationStorage2024}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Two-phases option selection process}}{7}{algocf.1}\protected@file@percent }
\newlabel{alg:decision}{{1}{7}{Option selection}{algocf.1}{}}
\newlabel{alg:decision1}{{2.2.1}{7}{Option selection}{algocf.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Learning}{7}{subsection.2.3}\protected@file@percent }
\citation{qiForcedExplorationBandit2023}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiments}{8}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Game variants}{8}{subsection.3.1}\protected@file@percent }
\newlabel{sec:envs}{{3.1}{8}{Game variants}{subsection.3.1}{}}
\citation{igelCovarianceMatrixAdaptation2007}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textsc  {Reward distribution for the four game variants} - \textit  {The reward distribution for each arm and environment is plotted over three trials of 1000, demarcated by a dotted grey line.}}}{9}{figure.caption.3}\protected@file@percent }
\newlabel{fig:envs}{{2}{9}{\textsc {Reward distribution for the four game variants} - \textit {The reward distribution for each arm and environment is plotted over three trials of 1000, demarcated by a dotted grey line.}}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Evolution search}{9}{subsection.3.2}\protected@file@percent }
\citation{citriSynapticPlasticityMultiple2008}
\citation{ojaOjaLearningRule2008}
\citation{kingmaAdamMethodStochastic2017}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textsc  {Evolution results} - \textbf  {a}: \textit  {top fitness, mean and standard deviation (as 16-84 percentile) of the population over generations.} - \textbf  {b}: \textit  {heatmap of the evolved parameters (rows) as histogram bins (y-axis) calculated from the 50 percentile of the population of the last generation; higher density is in dark blue} - \textbf  {c-d}: \textit  {Gaussian-sigmoid [c] and neural response functions [d] of the top-half of the population, the color intensity is proportional to the fitness.}}}{10}{figure.caption.4}\protected@file@percent }
\newlabel{fig:evolution}{{3}{10}{\textsc {Evolution results} - \textbf {a}: \textit {top fitness, mean and standard deviation (as 16-84 percentile) of the population over generations.} - \textbf {b}: \textit {heatmap of the evolved parameters (rows) as histogram bins (y-axis) calculated from the 50 percentile of the population of the last generation; higher density is in dark blue} - \textbf {c-d}: \textit {Gaussian-sigmoid [c] and neural response functions [d] of the top-half of the population, the color intensity is proportional to the fitness.}}{figure.caption.4}{}}
\citation{ratteImpactNeuronalProperties2013}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Environment variants and number of arms}{11}{subsection.3.3}\protected@file@percent }
\newlabel{tab:results}{{3.3}{11}{Environment variants and number of arms}{table.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Analysis of dynamics and robustness}{11}{subsection.3.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Entropy analysis}{11}{subsubsection.3.4.1}\protected@file@percent }
\newlabel{sec:entropy}{{3.4.1}{11}{Entropy analysis}{subsubsection.3.4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \textsc  {Table of performance} - \textit  {From the top: results for MAB-P, MAB-D, MAB-$\sin $, MAB-$\sin $P for different numbers $K$ of arms. Average regret and standard deviation (2 decimal places) over 2 trials of 2000 rounds each averaged over 5 simulations.}}}{12}{table.caption.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textsc  {Decision-making dynamics for different models} - \textbf  {a}: \textit  {Each plot display the results from one model. The raster plots (black dots) show the arms selected at each round. The red lines represent the entropy level, calculated from the distribution of selections over the preceeding 20 rounds, smoothed with a 30-steps moving average. In the plot titles, the total reward and average entropy over all trials are also reported.} - \textbf  {b}: \textit  {the top two rows display the average reward for trial 1 and 2 obtained by each model for increasing levels of entropy (in nats) in the reward distribution; a dashed line is the regret with respect to the upper bound (black solid line). The two bottom average entropy of the selections for the first and second trial of the simulation, each with 2000 rounds.}}}{13}{figure.caption.6}\protected@file@percent }
\newlabel{fig:entropy_fig1}{{4}{13}{\textsc {Decision-making dynamics for different models} - \textbf {a}: \textit {Each plot display the results from one model. The raster plots (black dots) show the arms selected at each round. The red lines represent the entropy level, calculated from the distribution of selections over the preceeding 20 rounds, smoothed with a 30-steps moving average. In the plot titles, the total reward and average entropy over all trials are also reported.} - \textbf {b}: \textit {the top two rows display the average reward for trial 1 and 2 obtained by each model for increasing levels of entropy (in nats) in the reward distribution; a dashed line is the regret with respect to the upper bound (black solid line). The two bottom average entropy of the selections for the first and second trial of the simulation, each with 2000 rounds.}}{figure.caption.6}{}}
\citation{steyversBayesianAnalysisHuman2009a}
\citation{schulzFindingStructureMultiarmed2020}
\citation{zhangForgetfulBayesMyopic2013}
\citation{suttonReinforcementLearningProblem1998}
\citation{kennerleyDecisionMakingReward2011a}
\citation{khamassiChapter22Medial2013}
\citation{wangMetalearningNaturalArtificial2021}
\citation{toblerAdaptiveCodingReward2005}
\citation{roeschDopamineNeuronsEncode2007}
\citation{coolsChemistryAdaptiveMind2019}
\citation{ratteImpactNeuronalProperties2013}
\citation{ockerFlexibleNeuralConnectivity2020}
\citation{apicellaSurveyModernTrainable2021}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{14}{section.4}\protected@file@percent }
\citation{larsenSynapsetypespecificPlasticityLocal2015}
\citation{inglisModulationDopamineAdaptive2021}
\citation{iigayaAdaptiveLearningDecisionmaking2016}
\citation{blackmanTargetcellspecificShorttermPlasticity2013}
\citation{bartolHippocampalSpineHead2015}
\citation{arielIntrinsicVariabilityPv2012}
\citation{faisalNoiseNeuronsOther2012}
\citation{tokicAdaptiveEGreedyExploration2010}
\citation{tokicValueDifferenceBasedExploration2011}
\citation{cavenaghiNonStationaryMultiArmed2021}
\citation{qiForcedExplorationBandit2023}
\citation{nunesSpikingNeuralNetworks2022}
\bibdata{mkb_bibliography}
\bibcite{suttonReinforcementLearningProblem1998}{1}
\bibcite{nivEvolutionReinforcementLearning2002}{2}
\bibcite{averbeckTheoryChoiceBandit2015}{3}
\bibcite{agrawalAnalysisThompsonSampling2012}{4}
\bibcite{kaufmannThompsonSamplingAsymptotically2012}{5}
\bibcite{auerFinitetimeAnalysisMultiarmed2002}{6}
\bibcite{gittinsBanditProcessesDynamic1979}{7}
\bibcite{banMultifacetContextualBandits2021}{8}
\bibcite{tokicAdaptiveEGreedyExploration2010}{9}
\bibcite{tokicValueDifferenceBasedExploration2011}{10}
\bibcite{schmidgallBraininspiredLearningArtificial2024}{11}
\bibcite{hassabisNeuroscienceInspiredArtificialIntelligence2017}{12}
\bibcite{leeBraininspiredPredictiveCoding2022}{13}
\bibcite{liuSeeingBelievingBrainInspired2023}{14}
\bibcite{EvaluationBioInspiredModels}{15}
\bibcite{ReviewNeuroscienceInspiredMachine}{16}
\bibcite{garivierUpperConfidenceBoundPolicies2008}{17}
\bibcite{besbesStochasticMultiArmedBanditProblem2014}{18}
\bibcite{cavenaghiNonStationaryMultiArmed2021}{19}
\bibcite{odohertyAbstractRewardPunishment2001}{20}
\bibcite{ricebergRewardStabilityDetermines2012}{21}
\bibcite{tremblayRelativeRewardPreference1999}{22}
\bibcite{elliottDissociableFunctionsMedial2000}{23}
\bibcite{frankAnatomyDecisionStriatoorbitofrontal2006}{24}
\bibcite{carrollEncodingCertaintyBump2014}{25}
\bibcite{esnaola-acebesBumpAttractorDynamics2021}{26}
\bibcite{bariDynamicDecisionMaking2021}{27}
\bibcite{houstonMatchingBehavioursRewards2021}{28}
\bibcite{larsenSynapsetypespecificPlasticityLocal2015}{29}
\bibcite{blackmanTargetcellspecificShorttermPlasticity2013}{30}
\bibcite{bartolHippocampalSpineHead2015}{31}
\bibcite{arielIntrinsicVariabilityPv2012}{32}
\bibcite{inglisModulationDopamineAdaptive2021}{33}
\bibcite{iigayaAdaptiveLearningDecisionmaking2016}{34}
\bibcite{toblerAdaptiveCodingReward2005}{35}
\bibcite{schultzNeuralSubstratePrediction1997}{36}
\bibcite{didomenicoDopaminergicModulationPrefrontal2023}{37}
\bibcite{lohaniDopamineModulationPrefrontal2019}{38}
\bibcite{dardenneRolePrefrontalCortex2012}{39}
\bibcite{qiForcedExplorationBandit2023}{40}
\bibcite{lukChoiceCodingFrontal2013}{41}
\bibcite{kennerleyDecisionMakingReward2011a}{42}
\bibcite{khamassiChapter22Medial2013}{43}
\bibcite{funahashiPrefrontalContributionDecisionMaking2017}{44}
\bibcite{marcosDeterminingMonkeyFree2016}{45}
\bibcite{balewskiValueDynamicsAffect2023}{46}
\bibcite{martinRepresentationObjectConcepts2007a}{47}
\bibcite{ockerFlexibleNeuralConnectivity2020}{48}
\bibcite{apicellaSurveyModernTrainable2021}{49}
\bibcite{millerCombinedMechanismsNeural2019}{50}
\bibcite{backmanEffectsWorkingMemoryTraining2011}{51}
\bibcite{enelStableDynamicRepresentations2020}{52}
\bibcite{citriSynapticPlasticityMultiple2008}{53}
\bibcite{kennedySynapticSignalingLearning2016}{54}
\bibcite{samavatSynapticInformationStorage2024}{55}
\bibcite{igelCovarianceMatrixAdaptation2007}{56}
\bibcite{ojaOjaLearningRule2008}{57}
\bibcite{kingmaAdamMethodStochastic2017}{58}
\bibcite{ratteImpactNeuronalProperties2013}{59}
\bibcite{steyversBayesianAnalysisHuman2009a}{60}
\bibcite{schulzFindingStructureMultiarmed2020}{61}
\bibcite{zhangForgetfulBayesMyopic2013}{62}
\bibcite{wangMetalearningNaturalArtificial2021}{63}
\bibcite{roeschDopamineNeuronsEncode2007}{64}
\bibcite{coolsChemistryAdaptiveMind2019}{65}
\bibcite{faisalNoiseNeuronsOther2012}{66}
\bibcite{nunesSpikingNeuralNetworks2022}{67}
\@writefile{toc}{\contentsline {section}{\numberline {5}Appendix}{22}{section.5}\protected@file@percent }
\newlabel{sec:appendix}{{5}{22}{Appendix}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Neural response function}{22}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Gaussian-sigmoid function}{22}{subsection.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textsc  {Activation function $\Phi _{v}$} - \textit  {Parameters $\beta =10$, $\alpha =1$, $\mu =1$, $\sigma =1$, and $r=0.5$.}}}{23}{figure.caption.8}\protected@file@percent }
\newlabel{fig:gau_sigm}{{5}{23}{\textsc {Activation function $\Phi _{v}$} - \textit {Parameters $\beta =10$, $\alpha =1$, $\mu =1$, $\sigma =1$, and $r=0.5$.}}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Evolution search}{23}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Genome distribution}{24}{subsubsection.5.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textsc  {Genome distribution} - \textit  {each parameter is plotted against the fitness score.}}}{25}{figure.caption.9}\protected@file@percent }
\newlabel{fig:evo_tabplot}{{6}{25}{\textsc {Genome distribution} - \textit {each parameter is plotted against the fitness score.}}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Reward distribution entropy}{25}{subsection.5.4}\protected@file@percent }
\newlabel{sec:appendix_entropy}{{5.4}{25}{Reward distribution entropy}{subsection.5.4}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Reward Probability Distribution Generation}}{26}{algocf.2}\protected@file@percent }
\newlabel{alg:reward_distribution}{{2}{26}{Reward distribution entropy}{algocf.2}{}}
\newlabel{alg:entr_alg}{{5.4}{26}{Reward distribution entropy}{algocf.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Weight update dynamics}{26}{subsection.5.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textsc  {Weight update developement for the model} \textit  {The plot displays the weight update quantity $\Delta W_{k}^{UV}$ for each round (blue line), smoothed as a 20-steps moving average. It is also reported the average reward in a window of 30 rounds (orange line). The results have been obtained averaging over 30 iterations.}}}{27}{figure.caption.10}\protected@file@percent }
\newlabel{fig:rew_update}{{7}{27}{\textsc {Weight update developement for the model} \textit {The plot displays the weight update quantity $\Delta W_{k}^{UV}$ for each round (blue line), smoothed as a 20-steps moving average. It is also reported the average reward in a window of 30 rounds (orange line). The results have been obtained averaging over 30 iterations.}}{figure.caption.10}{}}
\gdef \@abspage@last{27}
