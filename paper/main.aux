\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{unsrt}
\providecommand \oddpage@label [2]{}
\citation{millerIntegrativeTheoryPrefrontal2001a}
\citation{sheynikhovichLongtermMemorySynaptic2023}
\citation{odohertyAbstractRewardPunishment2001}
\citation{ricebergRewardStabilityDetermines2012}
\citation{tremblayRelativeRewardPreference1999}
\citation{elliottDissociableFunctionsMedial2000}
\citation{frankAnatomyDecisionStriatoorbitofrontal2006}
\citation{suttonReinforcementLearningProblem1998}
\citation{nivEvolutionReinforcementLearning2002}
\citation{averbeckTheoryChoiceBandit2015}
\citation{suttonReinforcementLearningProblem1998}
\citation{agrawalAnalysisThompsonSampling2012}
\citation{kaufmannThompsonSamplingAsymptotically2012}
\citation{auerFinitetimeAnalysisMultiarmed2002}
\citation{gittinsBanditProcessesDynamic1979}
\citation{banMultifacetContextualBandits2021}
\citation{tokicAdaptiveEGreedyExploration2010}
\citation{tokicValueDifferenceBasedExploration2011}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\citation{garivierUpperConfidenceBoundPolicies2008}
\citation{besbesStochasticMultiArmedBanditProblem2014}
\citation{cavenaghiNonStationaryMultiArmed2021}
\citation{carrollEncodingCertaintyBump2014}
\citation{esnaola-acebesBumpAttractorDynamics2021}
\citation{bariDynamicDecisionMaking2021}
\citation{houstonMatchingBehavioursRewards2021}
\citation{larsenSynapsetypespecificPlasticityLocal2015}
\citation{blackmanTargetcellspecificShorttermPlasticity2013}
\citation{bartolHippocampalSpineHead2015}
\citation{arielIntrinsicVariabilityPv2012}
\citation{inglisModulationDopamineAdaptive2021}
\citation{iigayaAdaptiveLearningDecisionmaking2016}
\citation{toblerAdaptiveCodingReward2005}
\citation{schultzNeuralSubstratePrediction1997}
\citation{didomenicoDopaminergicModulationPrefrontal2023}
\citation{lohaniDopamineModulationPrefrontal2019}
\citation{dardenneRolePrefrontalCortex2012}
\citation{qiForcedExplorationBandit2023}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methods}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Binomial K-armed bandit problem}{5}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Model description}{5}{subsection.2.2}\protected@file@percent }
\citation{ockerFlexibleNeuralConnectivity2020}
\citation{apicellaSurveyModernTrainable2021}
\citation{millerCombinedMechanismsNeural2019}
\newlabel{eq:main}{{2.2}{6}{Model description}{equation.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textsc  {Model architecture} - \textit  {The model is composed of a layer $U$ (blue), receiving a feedfoward input $I_{\text  {ext}}$, a layer $V$ (orange), and connections $\textbf  {W}^{UV}$ and $\textbf  {W}^{VU}$. Additionally, two indexes $k_{U}, k_{V}$ can be extracted from the layers and corresponds to the selection made by the two populations as $k_{U}=\text  {argmax}_{k} \{\textbf  {u}\}$, $k_{V}=\text  {argmax}_{k} \{\textbf  {v}\}$.}}}{6}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:main_architecture}{{1}{6}{\textsc {Model architecture} - \textit {The model is composed of a layer $U$ (blue), receiving a feedfoward input $I_{\text {ext}}$, a layer $V$ (orange), and connections $\textbf {W}^{UV}$ and $\textbf {W}^{VU}$. Additionally, two indexes $k_{U}, k_{V}$ can be extracted from the layers and corresponds to the selection made by the two populations as $k_{U}=\text {argmax}_{k} \{\textbf {u}\}$, $k_{V}=\text {argmax}_{k} \{\textbf {v}\}$.}}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Option selection}{7}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{alg:decision1}{{2.2.1}{7}{Option selection}{algocf.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Learning}{7}{subsection.2.3}\protected@file@percent }
\citation{larsenSynapsetypespecificPlasticityLocal2015}
\citation{citriSynapticPlasticityMultiple2008}
\citation{kennedySynapticSignalingLearning2016}
\citation{samavatSynapticInformationStorage2024}
\citation{igelCovarianceMatrixAdaptation2007}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Two-phases option selection process}}{8}{algocf.1}\protected@file@percent }
\newlabel{alg:decision}{{1}{8}{Option selection}{algocf.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Evolution search}{8}{subsection.2.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textsc  {Selection evolution over rounds} - \textit  {the y-axis represents the available arms, while the x-axis the number of rounds, with the dotted vertical lines indicating the start of a new trial with 150 rounds each. The model selections are the black vertical lines for an arm and a round. The red horizontal lines signal the arm with the highest reward probability, thus representing the best (and greediest) selection.}}}{9}{figure.caption.4}\protected@file@percent }
\newlabel{fig:sel1}{{2}{9}{\textsc {Selection evolution over rounds} - \textit {the y-axis represents the available arms, while the x-axis the number of rounds, with the dotted vertical lines indicating the start of a new trial with 150 rounds each. The model selections are the black vertical lines for an arm and a round. The red horizontal lines signal the arm with the highest reward probability, thus representing the best (and greediest) selection.}}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textsc  {Evolution of the model over generations.} - Left: \textit  {top fitness, mean and standard deviation (16-84 percentile) of the population over generations.} - Top-Right: \textit  {option value and learning rate Gaussian sigmoid functions parametrized according to the genome of the fittest individual} Bottom-Right: \textit  {activation function for population $v$ and $u$}}}{9}{figure.caption.5}\protected@file@percent }
\newlabel{fig:evolution}{{3}{9}{\textsc {Evolution of the model over generations.} - Left: \textit {top fitness, mean and standard deviation (16-84 percentile) of the population over generations.} - Top-Right: \textit {option value and learning rate Gaussian sigmoid functions parametrized according to the genome of the fittest individual} Bottom-Right: \textit {activation function for population $v$ and $u$}}{figure.caption.5}{}}
\citation{citriSynapticPlasticityMultiple2008}
\citation{ojaOjaLearningRule2008}
\citation{kingmaAdamMethodStochastic2017}
\citation{lukChoiceCodingFrontal2013}
\citation{kennerleyDecisionMakingReward2011a}
\citation{khamassiChapter22Medial2013}
\citation{funahashiPrefrontalContributionDecisionMaking2017}
\citation{marcosDeterminingMonkeyFree2016}
\citation{balewskiValueDynamicsAffect2023}
\citation{backmanEffectsWorkingMemoryTraining2011}
\citation{enelStableDynamicRepresentations2020}
\citation{wangMetalearningNaturalArtificial2021}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Bio-inspired features}{10}{subsection.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiments}{11}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Game variants}{11}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Environment variants and number of arms}{11}{subsection.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textsc  {Performance comparison for different values of $K$ and game variants} - \textit  {The models are evaluated on the four variants of the bandit problem, and their performance is measured as the average reward obtained over 2 trials of 2000 rounds each.}}}{12}{figure.caption.6}\protected@file@percent }
\newlabel{fig:perf_plot}{{4}{12}{\textsc {Performance comparison for different values of $K$ and game variants} - \textit {The models are evaluated on the four variants of the bandit problem, and their performance is measured as the average reward obtained over 2 trials of 2000 rounds each.}}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Decision-making dynamics}{12}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Entropy analysis}{12}{subsubsection.3.3.1}\protected@file@percent }
\newlabel{sec:entropy}{{3.3.1}{12}{Entropy analysis}{subsubsection.3.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textsc  {Decision-making dynamics for different models} \textit  {Each plot display the results from one model. The raster plots (black dots) show the arms selected at each round. The red lines represent the entropy level, calculated from the distribution of selections over the preceeding 20 rounds, smoothed with a 30-steps moving average. In the plot titles, the total reward and average entropy over all trials are also reported.}}}{13}{figure.caption.7}\protected@file@percent }
\newlabel{fig:entropy_fig1}{{5}{13}{\textsc {Decision-making dynamics for different models} \textit {Each plot display the results from one model. The raster plots (black dots) show the arms selected at each round. The red lines represent the entropy level, calculated from the distribution of selections over the preceeding 20 rounds, smoothed with a 30-steps moving average. In the plot titles, the total reward and average entropy over all trials are also reported.}}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Robustness}{13}{subsubsection.3.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textsc  {Entropy analysis for the model in a stationary setting} - Top row: \textit  {trial 1 and 2 have been divided into two columns. A solid line represents the average reward obtained by a model for increasing levels of entropy in the reward distribution; a dashed line instead reports the regret with respect to the upper bound (black solid line) } - Bottom row: \textit  {average entropy of the selections for the first and second trial of the simulation, each with 2000 rounds each (as calculated in \ref {sec:entropy}).}}}{14}{figure.caption.8}\protected@file@percent }
\newlabel{fig:entropy_distr}{{3.3.2}{14}{Robustness}{figure.caption.8}{}}
\citation{steyversBayesianAnalysisHuman2009a}
\citation{schulzFindingStructureMultiarmed2020}
\citation{zhangForgetfulBayesMyopic2013}
\citation{suttonReinforcementLearningProblem1998}
\citation{wangMetalearningNaturalArtificial2021}
\citation{toblerAdaptiveCodingReward2005}
\citation{roeschDopamineNeuronsEncode2007}
\citation{coolsChemistryAdaptiveMind2019}
\citation{larsenSynapsetypespecificPlasticityLocal2015}
\citation{inglisModulationDopamineAdaptive2021}
\citation{iigayaAdaptiveLearningDecisionmaking2016}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{15}{section.4}\protected@file@percent }
\citation{faisalNoiseNeuronsOther2012}
\citation{tokicAdaptiveEGreedyExploration2010}
\citation{tokicValueDifferenceBasedExploration2011}
\citation{nunesSpikingNeuralNetworks2022}
\bibdata{mkb_bibliography}
\bibcite{millerIntegrativeTheoryPrefrontal2001a}{1}
\bibcite{sheynikhovichLongtermMemorySynaptic2023}{2}
\bibcite{odohertyAbstractRewardPunishment2001}{3}
\bibcite{ricebergRewardStabilityDetermines2012}{4}
\bibcite{tremblayRelativeRewardPreference1999}{5}
\bibcite{elliottDissociableFunctionsMedial2000}{6}
\bibcite{frankAnatomyDecisionStriatoorbitofrontal2006}{7}
\bibcite{suttonReinforcementLearningProblem1998}{8}
\bibcite{nivEvolutionReinforcementLearning2002}{9}
\bibcite{averbeckTheoryChoiceBandit2015}{10}
\bibcite{agrawalAnalysisThompsonSampling2012}{11}
\bibcite{kaufmannThompsonSamplingAsymptotically2012}{12}
\bibcite{auerFinitetimeAnalysisMultiarmed2002}{13}
\bibcite{gittinsBanditProcessesDynamic1979}{14}
\bibcite{banMultifacetContextualBandits2021}{15}
\bibcite{tokicAdaptiveEGreedyExploration2010}{16}
\bibcite{tokicValueDifferenceBasedExploration2011}{17}
\bibcite{garivierUpperConfidenceBoundPolicies2008}{18}
\bibcite{besbesStochasticMultiArmedBanditProblem2014}{19}
\bibcite{cavenaghiNonStationaryMultiArmed2021}{20}
\bibcite{carrollEncodingCertaintyBump2014}{21}
\bibcite{esnaola-acebesBumpAttractorDynamics2021}{22}
\bibcite{bariDynamicDecisionMaking2021}{23}
\bibcite{houstonMatchingBehavioursRewards2021}{24}
\bibcite{larsenSynapsetypespecificPlasticityLocal2015}{25}
\bibcite{blackmanTargetcellspecificShorttermPlasticity2013}{26}
\bibcite{bartolHippocampalSpineHead2015}{27}
\bibcite{arielIntrinsicVariabilityPv2012}{28}
\bibcite{inglisModulationDopamineAdaptive2021}{29}
\bibcite{iigayaAdaptiveLearningDecisionmaking2016}{30}
\bibcite{toblerAdaptiveCodingReward2005}{31}
\bibcite{schultzNeuralSubstratePrediction1997}{32}
\bibcite{didomenicoDopaminergicModulationPrefrontal2023}{33}
\bibcite{lohaniDopamineModulationPrefrontal2019}{34}
\bibcite{dardenneRolePrefrontalCortex2012}{35}
\bibcite{qiForcedExplorationBandit2023}{36}
\bibcite{ockerFlexibleNeuralConnectivity2020}{37}
\bibcite{apicellaSurveyModernTrainable2021}{38}
\bibcite{millerCombinedMechanismsNeural2019}{39}
\bibcite{citriSynapticPlasticityMultiple2008}{40}
\bibcite{kennedySynapticSignalingLearning2016}{41}
\bibcite{samavatSynapticInformationStorage2024}{42}
\bibcite{igelCovarianceMatrixAdaptation2007}{43}
\bibcite{ojaOjaLearningRule2008}{44}
\bibcite{kingmaAdamMethodStochastic2017}{45}
\bibcite{lukChoiceCodingFrontal2013}{46}
\bibcite{kennerleyDecisionMakingReward2011a}{47}
\bibcite{khamassiChapter22Medial2013}{48}
\bibcite{funahashiPrefrontalContributionDecisionMaking2017}{49}
\bibcite{marcosDeterminingMonkeyFree2016}{50}
\bibcite{balewskiValueDynamicsAffect2023}{51}
\bibcite{backmanEffectsWorkingMemoryTraining2011}{52}
\bibcite{enelStableDynamicRepresentations2020}{53}
\bibcite{wangMetalearningNaturalArtificial2021}{54}
\bibcite{steyversBayesianAnalysisHuman2009a}{55}
\bibcite{schulzFindingStructureMultiarmed2020}{56}
\bibcite{zhangForgetfulBayesMyopic2013}{57}
\bibcite{roeschDopamineNeuronsEncode2007}{58}
\bibcite{coolsChemistryAdaptiveMind2019}{59}
\bibcite{faisalNoiseNeuronsOther2012}{60}
\bibcite{nunesSpikingNeuralNetworks2022}{61}
\@writefile{toc}{\contentsline {section}{\numberline {5}Appendix}{22}{section.5}\protected@file@percent }
\newlabel{sec:appendix}{{5}{22}{Appendix}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Neural response function}{22}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Gaussian-sigmoid function}{22}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Evolution search}{22}{subsection.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textsc  {Activation function $\Phi _{v}$} - \textit  {Parameters $\beta =10$, $\alpha =1$, $\mu =1$, $\sigma =1$, and $r=0.5$.}}}{23}{figure.caption.10}\protected@file@percent }
\newlabel{fig:gau_sigm}{{7}{23}{\textsc {Activation function $\Phi _{v}$} - \textit {Parameters $\beta =10$, $\alpha =1$, $\mu =1$, $\sigma =1$, and $r=0.5$.}}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Reward distribution entropy}{24}{subsection.5.4}\protected@file@percent }
\newlabel{sec:appendix_entropy}{{5.4}{24}{Reward distribution entropy}{subsection.5.4}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Reward Probability Distribution Generation}}{24}{algocf.2}\protected@file@percent }
\newlabel{alg:reward_distribution}{{2}{24}{Reward distribution entropy}{algocf.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Table of results}{24}{subsection.5.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Weight update dynamics}{25}{subsection.5.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textsc  {Weight update developement for the model} \textit  {The plot displays the weight update quantity $\Delta W_{k}^{UV}$ for each round (blue line), smoothed as a 20-steps moving average. It is also reported the average reward in a window of 30 rounds (orange line). The results have been obtained averaging over 20 iterations.}}}{25}{figure.caption.12}\protected@file@percent }
\newlabel{fig:rew_update}{{8}{25}{\textsc {Weight update developement for the model} \textit {The plot displays the weight update quantity $\Delta W_{k}^{UV}$ for each round (blue line), smoothed as a 20-steps moving average. It is also reported the average reward in a window of 30 rounds (orange line). The results have been obtained averaging over 20 iterations.}}{figure.caption.12}{}}
\gdef \@abspage@last{25}
